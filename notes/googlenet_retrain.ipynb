{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "def unpickle(file):\n",
    "    \"\"\"load the cifar-10 data\"\"\"\n",
    "\n",
    "    with open(file, 'rb') as fo:\n",
    "        data = pickle.load(fo, encoding='bytes')\n",
    "    return data\n",
    "\n",
    "def load_cifar_10_data(data_dir, negatives=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Return train_data, train_filenames, train_labels, test_data, test_filenames, test_labels\n",
    "    \"\"\"\n",
    "\n",
    "    # get the meta_data_dict\n",
    "    # num_cases_per_batch: 1000\n",
    "    # label_names: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    # num_vis: :3072\n",
    "\n",
    "    meta_data_dict = unpickle(data_dir + \"/batches.meta\")\n",
    "    cifar_label_names = meta_data_dict[b'label_names']\n",
    "    cifar_label_names = np.array(cifar_label_names)\n",
    "\n",
    "    # training data\n",
    "    cifar_train_data = None\n",
    "    cifar_train_filenames = []\n",
    "    cifar_train_labels = []\n",
    "\n",
    "    # cifar_train_data_dict\n",
    "    # 'batch_label': 'training batch 5 of 5'\n",
    "    # 'data': ndarray\n",
    "    # 'filenames': list\n",
    "    # 'labels': list\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        cifar_train_data_dict = unpickle(data_dir + \"/data_batch_{}\".format(i))\n",
    "        if i == 1:\n",
    "            cifar_train_data = cifar_train_data_dict[b'data']\n",
    "        else:\n",
    "            cifar_train_data = np.vstack((cifar_train_data, cifar_train_data_dict[b'data']))\n",
    "        cifar_train_filenames += cifar_train_data_dict[b'filenames']\n",
    "        cifar_train_labels += cifar_train_data_dict[b'labels']\n",
    "\n",
    "    cifar_train_data = cifar_train_data.reshape((len(cifar_train_data), 3, 32, 32))\n",
    "    if negatives:\n",
    "        cifar_train_data = cifar_train_data.transpose(0, 2, 3, 1).astype(np.float32)\n",
    "    else:\n",
    "        cifar_train_data = np.rollaxis(cifar_train_data, 1, 4)\n",
    "    cifar_train_filenames = np.array(cifar_train_filenames)\n",
    "    cifar_train_labels = np.array(cifar_train_labels)\n",
    "\n",
    "    # test data\n",
    "    # cifar_test_data_dict\n",
    "    # 'batch_label': 'testing batch 1 of 1'\n",
    "    # 'data': ndarray\n",
    "    # 'filenames': list\n",
    "    # 'labels': list\n",
    "\n",
    "    cifar_test_data_dict = unpickle(data_dir + \"/test_batch\")\n",
    "    cifar_test_data = cifar_test_data_dict[b'data']\n",
    "    cifar_test_filenames = cifar_test_data_dict[b'filenames']\n",
    "    cifar_test_labels = cifar_test_data_dict[b'labels']\n",
    "\n",
    "    cifar_test_data = cifar_test_data.reshape((len(cifar_test_data), 3, 32, 32))\n",
    "    if negatives:\n",
    "        cifar_test_data = cifar_test_data.transpose(0, 2, 3, 1).astype(np.float32)\n",
    "    else:\n",
    "        cifar_test_data = np.rollaxis(cifar_test_data, 1, 4)\n",
    "    cifar_test_filenames = np.array(cifar_test_filenames)\n",
    "    cifar_test_labels = np.array(cifar_test_labels)\n",
    "\n",
    "    return cifar_train_data, cifar_train_filenames, cifar_train_labels, \\\n",
    "        cifar_test_data, cifar_test_filenames, cifar_test_labels, cifar_label_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from collections import namedtuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "try:\n",
    "    from torch.hub import load_state_dict_from_url\n",
    "except ImportError:\n",
    "    from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "#from .utils import load_state_dict_from_url\n",
    "from typing import Optional, Tuple, List, Callable, Any\n",
    "\n",
    "__all__ = ['GoogLeNet', 'googlenet', \"GoogLeNetOutputs\", \"_GoogLeNetOutputs\"]\n",
    "\n",
    "model_urls = {\n",
    "    # GoogLeNet ported from TensorFlow\n",
    "    'googlenet': 'https://download.pytorch.org/models/googlenet-1378be20.pth',\n",
    "}\n",
    "\n",
    "GoogLeNetOutputs = namedtuple('GoogLeNetOutputs', ['logits', 'aux_logits2', 'aux_logits1'])\n",
    "GoogLeNetOutputs.__annotations__ = {'logits': Tensor, 'aux_logits2': Optional[Tensor],\n",
    "                                    'aux_logits1': Optional[Tensor]}\n",
    "\n",
    "# Script annotations failed with _GoogleNetOutputs = namedtuple ...\n",
    "# _GoogLeNetOutputs set here for backwards compat\n",
    "_GoogLeNetOutputs = GoogLeNetOutputs\n",
    "\n",
    "\n",
    "def googlenet(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> \"GoogLeNet\":\n",
    "    r\"\"\"GoogLeNet (Inception v1) model architecture from\n",
    "    `\"Going Deeper with Convolutions\" <http://arxiv.org/abs/1409.4842>`_.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "        aux_logits (bool): If True, adds two auxiliary branches that can improve training.\n",
    "            Default: *False* when pretrained is True otherwise *True*\n",
    "        transform_input (bool): If True, preprocesses the input according to the method with which it\n",
    "            was trained on ImageNet. Default: *False*\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        if 'transform_input' not in kwargs:\n",
    "            kwargs['transform_input'] = True\n",
    "        if 'aux_logits' not in kwargs:\n",
    "            kwargs['aux_logits'] = False\n",
    "        if kwargs['aux_logits']:\n",
    "            warnings.warn('auxiliary heads in the pretrained googlenet model are NOT pretrained, '\n",
    "                          'so make sure to train them')\n",
    "        original_aux_logits = kwargs['aux_logits']\n",
    "        kwargs['aux_logits'] = True\n",
    "        kwargs['init_weights'] = False\n",
    "        model = GoogLeNet(**kwargs)\n",
    "        state_dict = load_state_dict_from_url(model_urls['googlenet'],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "        if not original_aux_logits:\n",
    "            model.aux_logits = False\n",
    "            model.aux1 = None  # type: ignore[assignment]\n",
    "            model.aux2 = None  # type: ignore[assignment]\n",
    "        return model\n",
    "\n",
    "    return GoogLeNet(**kwargs)\n",
    "\n",
    "\n",
    "class GoogLeNet(nn.Module):\n",
    "    __constants__ = ['aux_logits', 'transform_input']\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int = 1000,\n",
    "        aux_logits: bool = True,\n",
    "        transform_input: bool = False,\n",
    "        init_weights: Optional[bool] = None,\n",
    "        blocks: Optional[List[Callable[..., nn.Module]]] = None\n",
    "    ) -> None:\n",
    "        super(GoogLeNet, self).__init__()\n",
    "        if blocks is None:\n",
    "            blocks = [BasicConv2d, Inception, InceptionAux]\n",
    "        if init_weights is None:\n",
    "            warnings.warn('The default weight initialization of GoogleNet will be changed in future releases of '\n",
    "                          'torchvision. If you wish to keep the old behavior (which leads to long initialization times'\n",
    "                          ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n",
    "            init_weights = True\n",
    "        assert len(blocks) == 3\n",
    "        conv_block = blocks[0]\n",
    "        inception_block = blocks[1]\n",
    "        inception_aux_block = blocks[2]\n",
    "\n",
    "        self.aux_logits = aux_logits\n",
    "        self.transform_input = transform_input\n",
    "\n",
    "        self.conv1 = conv_block(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
    "        self.conv2 = conv_block(64, 64, kernel_size=1)\n",
    "        self.conv3 = conv_block(64, 192, kernel_size=3, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.inception3a = inception_block(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception3b = inception_block(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.inception4a = inception_block(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.inception4b = inception_block(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception4c = inception_block(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inception4d = inception_block(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.inception4e = inception_block(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.maxpool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.inception5a = inception_block(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception5b = inception_block(832, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "        if aux_logits:\n",
    "            self.aux1 = inception_aux_block(512, num_classes)\n",
    "            self.aux2 = inception_aux_block(528, num_classes)\n",
    "        else:\n",
    "            self.aux1 = None  # type: ignore[assignment]\n",
    "            self.aux2 = None  # type: ignore[assignment]\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "        \n",
    "        \n",
    "\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self) -> None:\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                import scipy.stats as stats\n",
    "                X = stats.truncnorm(-2, 2, scale=0.01)\n",
    "                values = torch.as_tensor(X.rvs(m.weight.numel()), dtype=m.weight.dtype)\n",
    "                values = values.view(m.weight.size())\n",
    "                with torch.no_grad():\n",
    "                    m.weight.copy_(values)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _transform_input(self, x: Tensor) -> Tensor:\n",
    "        if self.transform_input:\n",
    "            x_ch0 = torch.unsqueeze(x[:, 0], 1) * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
    "            x_ch1 = torch.unsqueeze(x[:, 1], 1) * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
    "            x_ch2 = torch.unsqueeze(x[:, 2], 1) * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
    "            x = torch.cat((x_ch0, x_ch1, x_ch2), 1)\n",
    "        return x\n",
    "\n",
    "    def _forward(self, x: Tensor) -> Tuple[Tensor, Optional[Tensor], Optional[Tensor]]:\n",
    "        # N x 3 x 224 x 224\n",
    "        x = self.conv1(x)\n",
    "        # N x 64 x 112 x 112\n",
    "        x = self.maxpool1(x)\n",
    "        # N x 64 x 56 x 56\n",
    "        x = self.conv2(x)\n",
    "        # N x 64 x 56 x 56\n",
    "        x = self.conv3(x)\n",
    "        # N x 192 x 56 x 56\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        # N x 192 x 28 x 28\n",
    "        x = self.inception3a(x)\n",
    "        # N x 256 x 28 x 28\n",
    "        x = self.inception3b(x)\n",
    "        # N x 480 x 28 x 28\n",
    "        x = self.maxpool3(x)\n",
    "        # N x 480 x 14 x 14\n",
    "        x = self.inception4a(x)\n",
    "        # N x 512 x 14 x 14\n",
    "        aux1 = torch.jit.annotate(Optional[Tensor], None)\n",
    "        if self.aux1 is not None:\n",
    "            if self.training:\n",
    "                aux1 = self.aux1(x)\n",
    "\n",
    "        x = self.inception4b(x)\n",
    "        # N x 512 x 14 x 14\n",
    "        x = self.inception4c(x)\n",
    "        # N x 512 x 14 x 14\n",
    "        x = self.inception4d(x)\n",
    "        # N x 528 x 14 x 14\n",
    "        aux2 = torch.jit.annotate(Optional[Tensor], None)\n",
    "        if self.aux2 is not None:\n",
    "            if self.training:\n",
    "                aux2 = self.aux2(x)\n",
    "\n",
    "        x = self.inception4e(x)\n",
    "        # N x 832 x 14 x 14\n",
    "        x = self.maxpool4(x)\n",
    "        # N x 832 x 7 x 7\n",
    "        x = self.inception5a(x)\n",
    "        # N x 832 x 7 x 7\n",
    "        x = self.inception5b(x)\n",
    "        # N x 1024 x 7 x 7\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        # N x 1024 x 1 x 1\n",
    "        x = torch.flatten(x, 1)\n",
    "        # N x 1024\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        # N x 1000 (num_classes)\n",
    "        return x, aux2, aux1\n",
    "\n",
    "    @torch.jit.unused\n",
    "    def eager_outputs(self, x: Tensor, aux2: Tensor, aux1: Optional[Tensor]) -> GoogLeNetOutputs:\n",
    "        if self.training and self.aux_logits:\n",
    "            return _GoogLeNetOutputs(x, aux2, aux1)\n",
    "        else:\n",
    "            return x   # type: ignore[return-value]\n",
    "\n",
    "    def forward(self, x: Tensor) -> GoogLeNetOutputs:\n",
    "        x = self._transform_input(x)\n",
    "        x, aux1, aux2 = self._forward(x)\n",
    "        aux_defined = self.training and self.aux_logits\n",
    "        if torch.jit.is_scripting():\n",
    "            if not aux_defined:\n",
    "                warnings.warn(\"Scripted GoogleNet always returns GoogleNetOutputs Tuple\")\n",
    "            return GoogLeNetOutputs(x, aux2, aux1)\n",
    "        else:\n",
    "            return self.eager_outputs(x, aux2, aux1)\n",
    "\n",
    "\n",
    "class Inception(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        ch1x1: int,\n",
    "        ch3x3red: int,\n",
    "        ch3x3: int,\n",
    "        ch5x5red: int,\n",
    "        ch5x5: int,\n",
    "        pool_proj: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(Inception, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch1 = conv_block(in_channels, ch1x1, kernel_size=1)\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            conv_block(in_channels, ch3x3red, kernel_size=1),\n",
    "            conv_block(ch3x3red, ch3x3, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            conv_block(in_channels, ch5x5red, kernel_size=1),\n",
    "            # Here, kernel_size=3 instead of kernel_size=5 is a known bug.\n",
    "            # Please see https://github.com/pytorch/vision/issues/906 for details.\n",
    "            conv_block(ch5x5red, ch5x5, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1, ceil_mode=True),\n",
    "            conv_block(in_channels, pool_proj, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        branch3 = self.branch3(x)\n",
    "        branch4 = self.branch4(x)\n",
    "\n",
    "        outputs = [branch1, branch2, branch3, branch4]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionAux(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        num_classes: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionAux, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.conv = conv_block(in_channels, 128, kernel_size=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(2048, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14\n",
    "        x = F.adaptive_avg_pool2d(x, (4, 4))\n",
    "        # aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4\n",
    "        x = self.conv(x)\n",
    "        # N x 128 x 4 x 4\n",
    "        x = torch.flatten(x, 1)\n",
    "        # N x 2048\n",
    "        x = F.relu(self.fc1(x), inplace=True)\n",
    "        # N x 1024\n",
    "        x = F.dropout(x, 0.7, training=self.training)\n",
    "        # N x 1024\n",
    "        x = self.fc2(x)\n",
    "        # N x 1000 (num_classes)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        **kwargs: Any\n",
    "    ) -> None:\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cifar10 load code: https://github.com/snatch59/load-cifar-10/blob/master/load_cifar_10.py\n",
    "\n",
    "model = googlenet(True)\n",
    "p1 = next(model.parameters())\n",
    "\n",
    "# change the fc layers to fit cifar10 dataset.\n",
    "model.fc = nn.Linear(1024, 10)\n",
    "import time\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    print(\"begin to train\")\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                #print(inputs.shape)\n",
    "                #print(labels.shape)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    \n",
    "                    if is_inception and phase == 'train':\n",
    "                        # we don't train aux_outputs here.\n",
    "                        pass\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    \n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        #output_id = torch.max(outputs,1)[1].float()\n",
    "                        #label_id = torch.max(labels,1)[1].long()\n",
    "                        \n",
    "                        #print(outputs)\n",
    "                        #print(labels)\n",
    "                        \n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase])\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase])\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "tensor(1.3447)\n"
     ]
    }
   ],
   "source": [
    "fpath = \"/home/brucesz/Downloads/cifar-10-batches-py\"\n",
    "train_data, train_filenames, train_labels, test_data, test_filenames, test_labels, label_names\\\n",
    "    = load_cifar_10_data(fpath)\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def make_data_loader(data, labels):\n",
    "    ret = {}\n",
    "    train_factor = 0.8\n",
    "    print(data.shape)\n",
    "    print(type(data))\n",
    "    train_num = int(data.shape[0]*train_factor)\n",
    "    \n",
    "    def makeTensor(da):\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        input_tensor = preprocess(Image.fromarray(da))\n",
    "        input_batch = input_tensor.unsqueeze(0)\n",
    "        return input_batch\n",
    "    \n",
    "    def make_one_hot(id):\n",
    "        #arr = np.array([0 for i in range(10)])\n",
    "        #arr[id] = 1\n",
    "        return torch.from_numpy(np.array([id]))\n",
    "        #pre_ret = torch.from_numpy(arr)\n",
    "        #eturn pre_ret.unsqueeze(0)\n",
    "    \n",
    "    data = data[:100,:]\n",
    "    labels = labels[:100]\n",
    "    \n",
    "    t_data = data[0:train_num, :]\n",
    "    t_data = [t_data[idx,:] for idx in range(len(t_data))]\n",
    "    \n",
    "    t_label = labels[0:train_num]\n",
    "    t_label = [t_label[idx] for idx in range(len(t_label))]\n",
    "    \n",
    "    ret_train = [(makeTensor(t_data[idx]),make_one_hot(t_label[idx])) for idx in range(len(t_data)) ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    v_data = data[:train_num:,]\n",
    "    v_label = labels[:train_num:,]\n",
    "     \n",
    "    v_data = [v_data[idx,:] for idx in range(len(v_data))]\n",
    "    v_label = [v_label[idx] for idx in range(len(v_label))]\n",
    "    ret_val = [ (makeTensor(v_data[idx]), make_one_hot(v_label[idx])) for idx in range(len(v_data))]\n",
    "    \n",
    "    ret[\"train\"] = ret_train\n",
    "    ret[\"val\"] = ret_val\n",
    "    \n",
    "    return ret\n",
    "    \n",
    "\n",
    "loader = make_data_loader(train_data, train_labels)\n",
    "#print((loader[\"train\"][0][0].shape))\n",
    "#print((loader[\"train\"][1][0]))\n",
    "\n",
    "\n",
    "entroy=nn.CrossEntropyLoss()\n",
    "input=torch.Tensor([[-0.7715, -0.6205,-0.2562]])\n",
    "target = torch.tensor([0])\n",
    "output = entroy(input, target)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "begin to train\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 2.6431 Acc: 0.0900\n",
      "val Loss: 2.3888 Acc: 0.1200\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 2.6619 Acc: 0.1100\n",
      "val Loss: 2.3855 Acc: 0.1300\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 2.5731 Acc: 0.1100\n",
      "val Loss: 2.4109 Acc: 0.0900\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 2.5192 Acc: 0.1000\n",
      "val Loss: 2.3500 Acc: 0.1200\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 2.4641 Acc: 0.0900\n",
      "val Loss: 2.3360 Acc: 0.1000\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 2.3702 Acc: 0.1200\n",
      "val Loss: 2.3735 Acc: 0.0700\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 2.3838 Acc: 0.1200\n",
      "val Loss: 2.4254 Acc: 0.0900\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 2.2095 Acc: 0.2000\n",
      "val Loss: 2.3722 Acc: 0.1300\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 2.0965 Acc: 0.2500\n",
      "val Loss: 2.3276 Acc: 0.1300\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 1.9422 Acc: 0.3000\n",
      "val Loss: 2.3898 Acc: 0.1500\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 1.7471 Acc: 0.3900\n",
      "val Loss: 2.3976 Acc: 0.2100\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 1.6049 Acc: 0.4600\n",
      "val Loss: 2.3975 Acc: 0.2300\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 1.4313 Acc: 0.5500\n",
      "val Loss: 2.5181 Acc: 0.1900\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 1.2457 Acc: 0.6100\n",
      "val Loss: 2.5523 Acc: 0.1800\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 1.1202 Acc: 0.7100\n",
      "val Loss: 2.8376 Acc: 0.1800\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 1.3069 Acc: 0.6300\n",
      "val Loss: 2.5807 Acc: 0.1800\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 1.2386 Acc: 0.6300\n",
      "val Loss: 2.7913 Acc: 0.1300\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 1.4424 Acc: 0.4700\n",
      "val Loss: 2.3126 Acc: 0.2100\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 1.4533 Acc: 0.5100\n",
      "val Loss: 2.3580 Acc: 0.2300\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 1.3811 Acc: 0.5400\n",
      "val Loss: 2.4588 Acc: 0.2100\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 1.1183 Acc: 0.6200\n",
      "val Loss: 2.7027 Acc: 0.1600\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.8197 Acc: 0.7600\n",
      "val Loss: 2.5266 Acc: 0.1600\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "params_to_update = model.parameters()\n",
    "print(type(params_to_update))\n",
    "optimizer_ft = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "\n",
    "train_model(model, loader, criterion, optimizer_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_deprecated(model):\n",
    "    from PIL import Image\n",
    "    from torchvision import transforms\n",
    "    input_image = Image.open(filename)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "    # move the input and model to GPU for speed if available\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "    # Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "    print(output[0])\n",
    "    # The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "    print(torch.nn.functional.softmax(output[0], dim=0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_arr_as_img(arr,idx):\n",
    "      #plt.imshow(filer[ :, :].detach(),cmap='gray')\n",
    "    plt.imshow(arr[idx])\n",
    "    plt.show()\n",
    "    \n",
    "print(\"train\",train_data.shape)\n",
    "print(\"train\",train_filenames)\n",
    "print(\"train\",train_labels.shape)\n",
    "\n",
    "print(\"test\", test_data.shape)\n",
    "print(\"test\", test_filenames)\n",
    "print(\"test\", test_labels.shape)\n",
    "\n",
    "print(\"label names\", label_names)\n",
    "len(label_names)\n",
    "f1 = train_data[0]\n",
    "\n",
    "print(f1.shape)\n",
    "show_arr_as_img(train_data, 0)\n",
    "show_arr_as_img(train_data,1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
