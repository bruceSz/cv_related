{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#from .utils import load_state_dict_from_url\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "try:\n",
    "    from torch.hub import load_state_dict_from_url\n",
    "except ImportError:\n",
    "    from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "\n",
    "__all__ = ['AlexNet', 'alexnet']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
    "}\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes: int = 1000) -> None:\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def get_features(self):\n",
    "        return self.features\n",
    "\n",
    "\n",
    "def alexnet(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> AlexNet:\n",
    "    r\"\"\"AlexNet model architecture from the\n",
    "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = AlexNet(**kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls['alexnet'],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_test_img_cat():\n",
    "    import os\n",
    "    target = \"cat.jpg\"\n",
    "    if os.path.exists(target):\n",
    "        return target\n",
    "    else:\n",
    "        import urllib\n",
    "        url, filename = (\"https://raw.githubusercontent.com/mrqwertyuiop/Dog-Cat-Image-Classification---Machine-Learning-Model-CNN/master/cat1.jpg\", target)\n",
    "        try: urllib.URLopener().retrieve(url, filename)\n",
    "        except: urllib.request.urlretrieve(url, filename)\n",
    "    return target\n",
    "\n",
    "def load_test_img():\n",
    "    import os\n",
    "    target = \"dog.jpg\"\n",
    "    if os.path.exists(target):\n",
    "        return target\n",
    "    else:\n",
    "        import urllib\n",
    "        url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", target)\n",
    "        try: urllib.URLopener().retrieve(url, filename)\n",
    "        except: urllib.request.urlretrieve(url, filename)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_model(isDog=True):\n",
    "    model = alexnet(True,True)\n",
    "    type(model)\n",
    "\n",
    "    if isDog:\n",
    "        filename = load_test_img()\n",
    "    else:\n",
    "        filename = load_test_img_cat()\n",
    "\n",
    "    from PIL import Image\n",
    "    from torchvision import transforms\n",
    "    input_image = Image.open(filename)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "    # batch 1 , channel 3, length * width 224 * 224\n",
    "    #print(input_batch.shape)\n",
    "    #torch.Size([1, 3, 224, 224])\n",
    "\n",
    "    # move the input and model to GPU for speed if available\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "    # Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "\n",
    "\n",
    "\n",
    "    print(torch.argmax((torch.nn.functional.softmax(output[0], dim=0))))\n",
    "    #print(\"all layers: \")\n",
    "    ##for k,mod in model.features.named_children():\n",
    "    #    print(k, mod)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_firstTwo_last_conv_filter(model):\n",
    "    \n",
    "    conv1 = dict(model.features.named_children())['0']\n",
    "    conv2 = dict(model.features.named_children())['3']\n",
    "    conv3 = dict(model.features.named_children())['6']\n",
    "    conv4 = dict(model.features.named_children())['10']\n",
    "\n",
    "    print(\"first layer:\",conv1)\n",
    "    print(\"second conv layer: \", conv2)\n",
    "    print((conv1.weight.shape))\n",
    "\n",
    "    plot_weights(conv1,  mean_input_channel=True)        \n",
    "    plot_weights(conv2, mean_input_channel=True)\n",
    "    #plot_weights(conv3, mean_input_channel=True)\n",
    "    plot_weights(conv4, mean_input_channel=True)\n",
    "\n",
    "\n",
    "def plot_weights(layer, mean_input_channel=False):\n",
    "    \n",
    "    num =  50 if layer.weight.shape[0] > 50 else layer.weight.shape[0]\n",
    "    #print(layer.weight.shape[0])\n",
    "    localw = layer.weight.cpu().clone()    \n",
    "    if mean_input_channel:\n",
    "        \n",
    "        plt.figure(figsize=(20, 17))\n",
    "        for i in range(1,num):\n",
    "            localw0 = localw[i]\n",
    "            #print(\"shape of filter: \", localw0.shape)\n",
    "        \n",
    "            if (len(localw0)) > 1:\n",
    "                localw0 = torch.mean(localw0,dim=0)\n",
    "                plt.subplot(9, 9, i+1) \n",
    "                plt.axis('off')\n",
    "                plt.imshow(localw0[ :, :].detach(),cmap='gray')\n",
    "            else:\n",
    "                print(\"xxxx\")\n",
    "                plt.subplot(9, 9, i+1) \n",
    "                plt.axis('off')\n",
    "                plt.imshow(localw0[0, :, :].detach(),cmap='gray')\n",
    "            \n",
    "\n",
    "    else:\n",
    "            \n",
    "        print(\"total of number of filter : \", len(localw))\n",
    "        for i in range(1,num):\n",
    "            localw0 = localw[i]\n",
    "            #print(localw0.shape)    \n",
    "            # mean of 3 channel.\n",
    "            #localw0 = torch.mean(localw0,dim=0)\n",
    "            # there should be 3(3 channels) 11 * 11 filter.\n",
    "            plt.figure(figsize=(20, 17))\n",
    "            if (len(localw0)) > 1:\n",
    "                for idx, filer in enumerate(localw0):\n",
    "                    plt.subplot(9, 9, idx+1) \n",
    "                    plt.axis('off')\n",
    "                    plt.imshow(filer[ :, :].detach(),cmap='gray')\n",
    "            else:\n",
    "                    plt.subplot(9, 9, idx+1) \n",
    "                    plt.axis('off')\n",
    "                    plt.imshow(localw0[0, :, :].detach(),cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = forward_model()\n",
    "#plot_firstTwo_last_conv_filter(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = forward_model(False)\n",
    "plot_firstTwo_last_conv_filter(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
